{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing pitfalls in CV with Bulk Modulus data\n",
    "### Julien Brenneck, July 2018\n",
    "Specifically showing how the CV score in model selection can be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sklearn modules\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, cross_val_predict, train_test_split, GridSearchCV, RandomizedSearchCV, LeaveOneOut, KFold\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Load featurizers and feature utility functions\n",
    "from matminer.featurizers.composition import ElementProperty\n",
    "from matminer.featurizers.composition import OxidationStates\n",
    "from matminer.featurizers.structure import DensityFeatures\n",
    "\n",
    "from matminer.utils.conversions import composition_to_oxidcomposition\n",
    "from matminer.utils.conversions import str_to_composition\n",
    "from matminer.utils.pipeline import DropExcluded, ItemSelector\n",
    "\n",
    "from matminer.datasets.dataframe_loader import load_elastic_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives progress bar for loops, fall back to default range\n",
    "try:\n",
    "    from tqdm import tnrange, tqdm_notebook, trange\n",
    "except ImportError:\n",
    "    def tnrange(n, desc=''):\n",
    "        return range(n)\n",
    "    trange=range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import seaborn\n",
    "seaborn.set_color_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bulk modulus / elastic tensor data from matminer.\n",
    "See pipeline notebook in matminer examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_elastic_tensor()  # loads dataset in a pandas DataFrame \n",
    "unwanted_columns = [\"volume\", \"nsites\", \"compliance_tensor\", \"elastic_tensor\", \n",
    "                    \"elastic_tensor_original\", \"K_Voigt\", \"G_Voigt\", \"K_Reuss\", \"G_Reuss\"]\n",
    "df = df.drop(unwanted_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate out values to be estimated\n",
    "y = df['K_VRH'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"composition\"] = df[\"formula\"].transform(str_to_composition)\n",
    "ep_feat = ElementProperty.from_preset(preset_name=\"magpie\")\n",
    "df = ep_feat.featurize_dataframe(df, col_id=\"composition\")  # input the \"composition\" column to the featurizer\n",
    "\n",
    "# can't use this util method in pipeline\n",
    "df[\"composition_oxid\"] = composition_to_oxidcomposition(df[\"composition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to remove before regression\n",
    "excluded = [\"G_VRH\", \"K_VRH\", \"elastic_anisotropy\", \"formula\", \"material_id\", \n",
    "            \"poisson_ratio\", \"structure\", \"composition\", \"composition_oxid\"]\n",
    "\n",
    "# featurization transformations\n",
    "featurizer = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('drop', DropExcluded(excluded)),\n",
    "        ('density', Pipeline([\n",
    "            ('select', ItemSelector(\"structure\")),\n",
    "            ('density_feat', DensityFeatures()),\n",
    "        ])),\n",
    "        ('oxidation', Pipeline([\n",
    "            ('select', ItemSelector(\"composition_oxid\")),\n",
    "            ('oxidation_feat', OxidationStates()),\n",
    "        ])),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit KRR\n",
    "Select specific splits to show the effect of overfitting in model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 396 candidates, totalling 3960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 904 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3960 out of 3960 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 19.376987085725023\n",
      "{'alpha': 990, 'gamma': 0.001}\n",
      "Test RMSE: 25.98573500510255\n",
      "Train RMSE: 11.594467339121131\n",
      "Nested CV RMSE: 20.6159966267333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.1s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=21221) #1211 #21 #31 #0 #1009 #21221\n",
    "np.random.seed(10)\n",
    "model = KernelRidge(kernel='poly', degree=2)\n",
    "param_grid = [{'alpha': np.arange(10,1000,10), 'gamma': 10.0**np.arange(-6.0,-2.0)}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_train, y_train, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 14.514982117572337\n",
      "{'max_depth': 1, 'n_estimators': 100000}\n",
      "Test RMSE: 20.869513321088625\n",
      "Train RMSE: 0.28845068533474844\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=21221) #1001 #12 #16 #21221 #1111\n",
    "np.random.seed(10)\n",
    "model = GradientBoostingRegressor()\n",
    "param_grid = [{'max_depth': [1,2], 'n_estimators': [10000]}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV RMSE: 16.380843360225082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "model = GradientBoostingRegressor()\n",
    "param_grid = [{'max_depth': [1,2], 'n_estimators': [10000]}]\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), n_jobs=1, scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_train, y_train, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    5.5s remaining:    8.2s\n",
      "/global/homes/j/jbrennec/rsconda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning:\n",
      "\n",
      "fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.60188]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 29, 'nit': 2, 'warnflag': 2}\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 32.95206389775767\n",
      "{'kernel': Matern(length_scale=1, nu=0.25)}\n",
      "Test RMSE: 35.68066267756345\n",
      "Train RMSE: 8.692384192839179e-07\n",
      "Nested CV RMSE: 33.301186322394344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.7s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=12) #1001 #12 #16 #21\n",
    "np.random.seed(10)\n",
    "model = GaussianProcessRegressor()\n",
    "param_grid = [{'kernel':[Matern(nu=0.25)]}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_train, y_train, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit MLP (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  70 | elapsed:    1.5s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 31.412817927918073\n",
      "{'alpha': 1e-05}\n",
      "Test RMSE: 34.56220762808273\n",
      "Train RMSE: 26.19117625094989\n",
      "Nested CV RMSE: 74.9726875815911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1001) #1001 #12 #16 #21\n",
    "np.random.seed(100)\n",
    "model = MLPRegressor()\n",
    "param_grid = [{'alpha': 10**np.arange(-8.0,-1.0)}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_train, y_train, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1001) #1001 #12 #16 #21\n",
    "np.random.seed(100)\n",
    "model = MLPRegressor()\n",
    "param_grid = [{'alpha': 10**np.arange(-8.0,-1.0)}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_train, y_train, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=111) #10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "model = RandomForestRegressor()\n",
    "param_grid = [{'n_estimators': np.arange(25, 500, 25)}]\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  cv=KFold(10, random_state=100),\n",
    "                  verbose=True,\n",
    "                  return_train_score=True,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"CV RMSE:\", np.sqrt(-gs.best_score_))\n",
    "# print(gs.best_params_)\n",
    "print(\"Test RMSE:\", np.sqrt(-gs.score(X_test, y_test)))\n",
    "print(\"Train RMSE:\", np.sqrt(-gs.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "model = RandomForestRegressor()\n",
    "param_grid = [{'n_estimators': np.arange(500, 550, 50)}]\n",
    "grid = GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "pipe = make_pipeline(grid)\n",
    "s = cross_val_score(pipe, X_test, y_test, cv=KFold(5), n_jobs=-1, verbose=True, scoring='neg_mean_squared_error')\n",
    "print(\"Nested CV RMSE:\", np.sqrt(np.mean(-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = list(x['n_estimators'] for x in gs.cv_results_['params'])\n",
    "plt.plot(x_scale, np.sqrt(-gs.cv_results_['mean_test_score']))\n",
    "# plt.plot(x_scale, np.sqrt(-gs.cv_results_['mean_train_score']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to try lots of different splits and look at results in aggregate\n",
    "next time use KRR for this as it runs quite fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTRIALS = 25\n",
    "# KCV_RMSE = np.zeros(NTRIALS)\n",
    "# TEST_RMSE = np.zeros(NTRIALS)\n",
    "# TRAIN_RMSE = np.zeros(NTRIALS)\n",
    "# NESTCV_RMSE = np.zeros(NTRIALS)\n",
    "\n",
    "# model = RandomForestRegressor()\n",
    "# param_grid = [{'n_estimators': np.arange(50, 300, 50)}]\n",
    "# gs = GridSearchCV(model, param_grid, n_jobs=-1, cv=KFold(25),\n",
    "#                   return_train_score=True, scoring='neg_mean_squared_error')\n",
    "# pipe = make_pipeline(GridSearchCV(model, param_grid, cv=KFold(5), scoring='neg_mean_squared_error'))\n",
    "# for i in trange(NTRIALS):\n",
    "#     _X_train, _X_test, _y_train, _y_test = train_test_split(X, y, test_size=0.5)\n",
    "#     gs.fit(_X_train, _y_train)\n",
    "#     _s = cross_val_score(pipe, _X_train, _y_train, cv=KFold(10), n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "#     KCV_RMSE[i] = np.sqrt(-gs.best_score_)\n",
    "#     TEST_RMSE[i] = np.sqrt(-gs.score(_X_test, _y_test))\n",
    "#     TRAIN_RMSE[i] = np.sqrt(-gs.score(_X_train, _y_train))\n",
    "#     NESTCV_RMSE[i] = np.sqrt(np.mean(-_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5))\n",
    "# x_s = np.arange(KCV_RMSE.size)\n",
    "# plt.hlines([np.mean(KCV_RMSE), np.mean(TEST_RMSE), np.mean(NESTCV_RMSE)], linestyles='--', xmin=0,xmax=KCV_RMSE.size-1, colors=['b', 'g', 'r'], zorder=0)\n",
    "# plt.scatter(x_s, KCV_RMSE, c='b', label='CV')\n",
    "# plt.scatter(x_s, TEST_RMSE, c='g', label='Test')\n",
    "# plt.scatter(x_s, NESTCV_RMSE, c='r', label='Nest')\n",
    "# # plt.scatter(x_s, TRAIN_RMSE, c='k', label='Train')\n",
    "# plt.xlabel(\"Trial\")\n",
    "# plt.ylabel(\"RMSE\")\n",
    "# plt.title(\"Overfitting CV Score in Model Selection\")\n",
    "# plt.legend()\n",
    "# # plt.savefig('overfit-cv-scores.pdf')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
